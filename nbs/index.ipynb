{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowflake Cortex Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowflake ML Forecast: From Code to Application\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the Snowflake ML Forecast tool! This project combines a powerful Python class for creating and managing forecast models with a user-friendly Streamlit application. Whether you're a developer looking to integrate forecasting into your Python scripts or an analyst wanting to quickly generate forecasts through a web interface, this tool has you covered.\n",
    "\n",
    "> Note: This is a POC and is not production ready. It's designed to get you 80-90% of the way there for simple forecasting use cases, serving as a starting point for your forecasting journey.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The project consists of three main components:\n",
    "\n",
    "1. SnowparkConnection Class: A Python class that manages the connection to Snowflake, handling authentication and session management.\n",
    "2. SnowflakeMLForecast Class: A Python class that interfaces with Snowflake to create, manage, and analyze forecast models.\n",
    "3. Streamlit Application: A web-based interface that makes it easy to configure and run forecasts without writing code.\n",
    "\n",
    "## SnowflakeMLForecast Class\n",
    "\n",
    "### Features\n",
    "\n",
    "- Dynamic forecast model creation using Snowflake's `CREATE SNOWFLAKE.ML.FORECAST` functionality\n",
    "- Visualization capabilities for forecast results\n",
    "- Tag management in Snowflake\n",
    "- Configurable via YAML files\n",
    "- Robust error handling\n",
    "\n",
    "### Installation\n",
    "\n",
    "1. Clone the repository\n",
    "2. Install dependencies:\n",
    "   ```\n",
    "   pip install snowflake-connector-python pandas altair streamlit\n",
    "   ```\n",
    "\n",
    "### Basic Usage\n",
    "\n",
    "```python\n",
    "from snowflake_ml_forecast import SnowflakeMLForecast\n",
    "\n",
    "# Setup connection config\n",
    "connection_config = {\n",
    "    'user': 'your_user',\n",
    "    'password': 'your_password',\n",
    "    'account': 'your_account',\n",
    "    'database': 'your_database',\n",
    "    'warehouse': 'your_warehouse',\n",
    "    'schema': 'your_schema',\n",
    "    'role': 'your_role'\n",
    "}\n",
    "\n",
    "# Create forecast model\n",
    "forecast_model = SnowflakeMLForecast(\n",
    "    config_file='path/to/your/config.yaml',\n",
    "    connection_config=connection_config\n",
    ")\n",
    "\n",
    "# Run forecast and visualize\n",
    "forecast_data = forecast_model.create_and_run_forecast()\n",
    "forecast_model.generate_forecast_and_visualization()\n",
    "\n",
    "# Clean up\n",
    "forecast_model.cleanup()\n",
    "```\n",
    "\n",
    "# Forecast Configuration Guide\n",
    "\n",
    "This guide provides a detailed explanation of all configuration options available for the Snowflake ML Forecast tool. The configuration is typically defined in a YAML file.\n",
    "\n",
    "## Configuration Structure\n",
    "\n",
    "The configuration is divided into four main sections:\n",
    "\n",
    "1. `model`: Defines the model's metadata\n",
    "2. `input_data`: Specifies the input data source and structure\n",
    "3. `forecast_config`: Sets up the forecasting parameters\n",
    "4. `output`: Defines where the forecast results will be stored\n",
    "\n",
    "Below is a detailed breakdown of each section:\n",
    "\n",
    "## 1. Model Configuration\n",
    "\n",
    "```yaml\n",
    "model:\n",
    "  name: my_taxi_forecast_model\n",
    "  tags:\n",
    "    environment: production\n",
    "    team: data_science\n",
    "  comment: \"Forecast model for predicting sales trends.\"\n",
    "```\n",
    "\n",
    "- `name` (required): A unique identifier for your model.\n",
    "- `tags` (optional): Key-value pairs for categorizing and organizing your models.\n",
    "  - `environment`: Typically set to 'development', 'production', or 'testing'.\n",
    "  - `team`: The team responsible for this model.\n",
    "- `comment` (optional): A description of the model's purpose or any relevant notes.\n",
    "\n",
    "## 2. Input Data Configuration\n",
    "\n",
    "```yaml\n",
    "input_data:\n",
    "  table: ny_taxi_rides_h3_train\n",
    "  table_type: table\n",
    "  timestamp_column: pickup_time\n",
    "  target_column: pickups\n",
    "  series_column: h3\n",
    "  exogenous_columns:\n",
    "  - PUBLIC_HOLIDAY\n",
    "  - SPORT_EVENT\n",
    "```\n",
    "\n",
    "- `table` (required): The name of the table or view containing your input data.\n",
    "- `table_type` (optional): Specifies whether the input is a 'table' or a 'view'. Default is 'table'.\n",
    "- `timestamp_column` (required): The name of the column containing timestamp data.\n",
    "- `target_column` (required): The name of the column containing the values you want to forecast.\n",
    "- `series_column` (optional): For multi-series forecasting, the column that identifies different series.\n",
    "- `exogenous_columns` (optional): A list of additional columns to be used as features in the forecast model.\n",
    "\n",
    "## 3. Forecast Configuration\n",
    "\n",
    "```yaml\n",
    "forecast_config:\n",
    "  training_days: 30\n",
    "  table: ny_taxi_rides_h3_predict\n",
    "  config_object:\n",
    "    on_error: skip\n",
    "    evaluate: true\n",
    "    evaluation_config:\n",
    "      n_splits: 2\n",
    "      gap: 0\n",
    "      prediction_interval: 0.95\n",
    "```\n",
    "\n",
    "- `training_days` (optional): The number of days of historical data to use for training. If not specified, all available data will be used.\n",
    "- `table` (optional): If specified, the model will create predictions for the data in this table instead of forecasting future dates.\n",
    "- `config_object`: Advanced configuration options for the forecasting process.\n",
    "  - `on_error` (optional): Determines behavior when an error occurs. Options are 'skip' or 'fail'. Default is 'skip'.\n",
    "  - `evaluate` (optional): Whether to perform model evaluation. Default is true.\n",
    "  - `evaluation_config`: Settings for the evaluation process.\n",
    "    - `n_splits` (optional): Number of splits for cross-validation. Default is 2.\n",
    "    - `test_size` (optional): Size of the test set in days. If not specified, it will be automatically determined.\n",
    "    - `gap` (optional): Number of days between the training and test sets. Default is 0.\n",
    "    - `prediction_interval` (optional): Confidence level for prediction intervals. Default is 0.95 (95% confidence).\n",
    "\n",
    "## 4. Output Configuration\n",
    "\n",
    "```yaml\n",
    "output:\n",
    "  table: taxi_forecast_results\n",
    "```\n",
    "\n",
    "- `table` (required): The name of the table where forecast results will be stored.\n",
    "\n",
    "## Usage Notes\n",
    "\n",
    "1. Ensure all required fields are filled out correctly.\n",
    "2. For multi-series forecasting, make sure to specify the `series_column`.\n",
    "3. Choose `exogenous_columns` carefully - they should be variables that you expect to have a significant impact on your target variable.\n",
    "4. When using `training_days`, ensure you have enough historical data to cover the specified period.\n",
    "5. If you specify a `table` in `forecast_config`, make sure it contains future dates or scenarios you want to predict.\n",
    "6. Adjust `evaluation_config` parameters based on your data characteristics and forecast horizon.\n",
    "\n",
    "\n",
    "The class uses a YAML file for configuration. Here's a simple example sample:\n",
    "\n",
    "```yaml\n",
    "model:\n",
    "  name: my_forecast_model\n",
    "  tags:\n",
    "    environment: production\n",
    "    team: data_science\n",
    "  comment: \"Forecast model for predicting trends.\"\n",
    "\n",
    "input_data:\n",
    "  table: storage_usage_train\n",
    "  timestamp_column: usage_date\n",
    "  target_column: storage_gb\n",
    "\n",
    "forecast_config:\n",
    "  training_days: 180\n",
    "  forecast_days: 30\n",
    "  config_object:\n",
    "    evaluate: true\n",
    "    evaluation_config:\n",
    "      prediction_interval: 0.95\n",
    "\n",
    "output:\n",
    "  table: storage_forecast_results\n",
    "```\n",
    "\n",
    "## Streamlit Application\n",
    "\n",
    "The Streamlit application provides a user-friendly interface to the SnowflakeMLForecast functionality.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- Choose between your own data or a pre-loaded example dataset\n",
    "- Step-by-step forecast configuration\n",
    "- Interactive visualization of results\n",
    "\n",
    "### How to Run the Application\n",
    "\n",
    "To run the Streamlit application, use the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "streamlit run streamlit_app.py\n",
    "```\n",
    "\n",
    "This will start the Streamlit server and open the application in your default web browser.\n",
    "\n",
    "### How to Use\n",
    "\n",
    "1. **Data Selection**\n",
    "\n",
    "   - Choose between your Snowflake data or the example dataset\n",
    "\n",
    "   - If using your data, select the database, schema, and table/view\n",
    "\n",
    "   - Specify timestamp, target, and optional series/exogenous columns\n",
    "\n",
    "\n",
    "2. **Forecast Configuration**\n",
    "\n",
    "   - Set model name, tags, and comments\n",
    "\n",
    "   - Configure forecast parameters (training days, forecast horizon)\n",
    "\n",
    "   - Set advanced options like evaluation settings\n",
    "\n",
    "3. **Model Execution**\n",
    "\n",
    "   - Review settings and run the forecast\n",
    "\n",
    "   - View results including charts and statistics\n",
    "\n",
    "\n",
    "## Tips for Best Results\n",
    "\n",
    "- Ensure consistent frequency in your time series data\n",
    "\n",
    "- Include sufficient historical data to capture seasonal patterns\n",
    "\n",
    "- Experiment with different configuration settings\n",
    "\n",
    "- For your own data, carefully select relevant exogenous variables\n",
    "\n",
    "Remember, these code snippets are integrated into the Streamlit application, allowing for an interactive experience. Users can modify parameters, load their own data, and see results in real-time through the web interface.\n",
    "\n",
    "## Versatility and Adaptability\n",
    "\n",
    "While this project showcases a powerful Streamlit application for interactive forecasting, it's important to note that the core functionality is highly versatile and can be easily integrated into various workflows:\n",
    "\n",
    "1. Python Scripts and Notebooks: The SnowflakeMLForecast class can be imported and used in your own Python scripts or Jupyter notebooks, allowing for seamless integration with your existing data processing pipelines.\n",
    "\n",
    "2. Automated Reporting: Leverage the forecasting capabilities in automated reporting systems, scheduling regular forecast updates without manual intervention.\n",
    "\n",
    "3. Custom Applications: Build your own applications around the SnowflakeMLForecast class, tailoring the user interface and functionality to your specific needs.\n",
    "\n",
    "4. Baseline for Advanced Models: Use this project as a starting point for more complex forecasting models, adding your own custom features or integrating with other machine learning libraries.\n",
    "\n",
    "Remember, while the Streamlit application provides a great out-of-the-box experience, the underlying SnowflakeMLForecast class is designed to be flexible and extensible. We encourage you to explore beyond the Streamlit interface and adapt the code to fit your unique forecasting requirements.\n",
    "Whether you're using the ready-made Streamlit application or integrating the core functionality into your own systems, this tool provides a solid foundation for leveraging Snowflake's ML capabilities for time series forecasting\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "Here's a simplified overview of the project structure:\n",
    "\n",
    "```\n",
    "cortex_forecast/\n",
    "├── cortex_forecast/\n",
    "│   ├── __init__.py\n",
    "│   ├── connection.py\n",
    "│   ├── forecast.py\n",
    "│   └── files/\n",
    "│       └── yaml/\n",
    "│           ├── storage_forecast_config.yaml\n",
    "│           └── taxi_forecast_config.yaml\n",
    "├── docs/\n",
    "│   ├── index.ipynb\n",
    "│   └── forecast_storage_example.ipynb\n",
    "├── nbs/\n",
    "│   ├── 00_connection.ipynb\n",
    "│   └── 01_cortex_forecast.ipynb\n",
    "├── pages/\n",
    "│   ├── 00_table_selection_creation_page.py\n",
    "│   ├── 01_create_forecast_config.py\n",
    "│   └── 02_modeling.py\n",
    "├── streamlit_app.py\n",
    "├── requirements.txt\n",
    "└── setup.py\n",
    "```\n",
    "\n",
    "Key components:\n",
    "\n",
    "- `cortex_forecast/`: Core Python package with the main functionality.\n",
    "\n",
    "- `docs/`: Documentation notebooks and examples.\n",
    "\n",
    "- `nbs/`: Development notebooks (using nbdev).\n",
    "\n",
    "- `pages/`: Streamlit application pages.\n",
    "\n",
    "- `streamlit_app.py`: Main Streamlit application entry point.\n",
    "\n",
    "This structure separates the core functionality (`cortex_forecast/`) from the Streamlit application (`pages/` and `streamlit_app.py`), while keeping documentation (`docs/`) and development notebooks (`nbs/`) organized.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Whether you're using the SnowflakeMLForecast class in your Python scripts or leveraging the Streamlit application for quick forecasts, this tool provides a flexible and powerful way to generate forecasts using Snowflake's ML capabilities. Start with the example data to get familiar with the process, then apply it to your own datasets for valuable insights.\n",
    "\n",
    "Happy forecasting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Example\n",
    "\n",
    "> See in Docs/ folder for two example of this in action. One is for storage and the other is for Taxi Pick up in NYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip\n",
    "from snowflake.snowpark.version import VERSION\n",
    "from cortex_forecast.forecast import SnowflakeMLForecast\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Snowflake Connection Using SnowflakeMLForecast\n",
    "\n",
    "\n",
    "> Note: Make sure that you create a yaml file that you would like to so that the SnowflakeMLForecast can read the connection information from it and be able to build your forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip\n",
    "forecast_model = SnowflakeMLForecast(\n",
    "   config='./cortex_forecast/files/yaml/storage_forecast_config.yaml',\n",
    "    connection_config={\n",
    "        'user': os.getenv('SNOWFLAKE_USER'),\n",
    "        'password': os.getenv('SNOWFLAKE_PASSWORD'),\n",
    "        'account': os.getenv('SNOWFLAKE_ACCOUNT'),\n",
    "        'database': 'CORTEX',\n",
    "        'warehouse': 'CORTEX_WH',\n",
    "        'schema': 'DEV',\n",
    "        'role': 'CORTEX_USER_ROLE'  # Use the desired role\n",
    "    },\n",
    "    is_streamlit=False\n",
    ")\n",
    "\n",
    "snowflake_environment = forecast_model.session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "print('\\nConnection Established with the following parameters:')\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0], snowpark_version[1], snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip\n",
    "# Create Training Data\n",
    "training_days = 365\n",
    "\n",
    "forecast_model.session.sql(f'''CREATE OR REPLACE TABLE storage_usage_train AS\n",
    "    SELECT \n",
    "        TO_TIMESTAMP_NTZ(usage_date) AS usage_date,\n",
    "        storage_bytes / POWER(1024, 3) AS storage_gb\n",
    "    FROM \n",
    "    (\n",
    "        SELECT * \n",
    "            FROM snowflake.account_usage.storage_usage\n",
    "            WHERE usage_date < CURRENT_DATE()\n",
    "    )\n",
    "    WHERE TO_TIMESTAMP_NTZ(usage_date) > DATEADD(day, -{training_days}, CURRENT_DATE())\n",
    "''').collect()\n",
    "forecast_model.session.sql('SELECT * FROM storage_usage_train ORDER BY usage_date DESC LIMIT 10').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip\n",
    "df = forecast_model.session.sql('SELECT * FROM storage_usage_train ORDER BY usage_date').to_pandas()\n",
    "df.head()\n",
    "df = df.set_index('USAGE_DATE')\n",
    "df['STORAGE_GB'].plot(figsize=(10, 6), title='Storage GB Over Time')\n",
    "\n",
    "# Show the plot\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Storage GB')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Model\n",
    "\n",
    "> This will use what is inside of the yaml file that you created that you passed over to the SnowflakeMLForecast object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip\n",
    "# Run Forecast\n",
    "forecast_data = forecast_model.create_and_run_forecast()\n",
    "forecast_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_model.generate_forecast_and_visualization(show_historical=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
